{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "'''\n",
    "This function is to generate data with binary label, based on the model of Logistic Regression\n",
    "'X' is sampled from a uniform distribution between [0,1]\n",
    "hypothesis 'h' is generated from a integer uniform distribution between [-5,5]\n",
    "the noise level 'sigma' is generated from a normal distribution with mean 0 and std sigma\n",
    "label y is generated in the way below:\n",
    "first generate y_linear=X*w+sigma as a linear problem\n",
    "and then use logistic regression model to transform y_linear to a probability between [0,1]\n",
    "and then generate a variable 'e' uniformly from [0,1], \n",
    "if y_linear>e ,set the label to be 1, otherwise set the label to be 0.\n",
    "\n",
    "Input: number of samples N,dimension of data d, noise level sigma\n",
    "\n",
    "Output: generate X, label y, realy hypothesis h\n",
    "'''\n",
    "\n",
    "def generate_data_lr(N,d,sigma):\n",
    "    # generate X uniform distributed between[-1,1]\n",
    "    X=np.random.uniform(-1,1,size=(N,d))\n",
    "    # generate noise normal distributed, mean 0, variance sigam^2\n",
    "    noise=np.random.normal(0.0,sigma,(N,1))\n",
    "    # add a collumnn of b so that the model is y=X*beta+b, \n",
    "    b=np.ones((N,1))\n",
    "    X_modify=np.concatenate((X,b),axis=1)\n",
    "    # generate hypothesis of the linear classification, it is d+1 dimension vector\n",
    "    h=np.random.uniform(-5.0,5.0,size=(d+1,1))\n",
    "    # generate value of y if it is a linear regression problem\n",
    "    y_linear=np.dot(X_modify,h)+noise\n",
    "    # transform y_linear into a  0-1 label based on logistic regression model\n",
    "    y=1 / (1 + np.exp(-y_linear))\n",
    "    for i in range(0,N):\n",
    "        e=np.random.uniform(0,1,size=(1,1))\n",
    "        if y[i,0]>=e:\n",
    "            y[i,0]=1\n",
    "        else:\n",
    "            y[i,0]=0\n",
    "    \n",
    "    return X,y,h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "function generate_cost_SampleGroup is to generate cost correlated with their group\n",
    "first randomly assign a group label for each sample, \n",
    "In each group, the cost is a normal distribution with a specific mean and variance\n",
    "Input:\n",
    "'Group_Number' is a integer showing the number of groups\n",
    "'Cost_Mean' is a 1-D vector contains the cost mean of each group\n",
    "'Cost_Var' is a 1-D vector contains the cost variance of each group\n",
    "'X' generated data\n",
    "'cost_sg' is a sample\n",
    "'''\n",
    "\n",
    "\n",
    "def generate_cost_SampleGroup(Group_Number,Cost_Mean,Cost_Var,X):\n",
    "    # number of samples\n",
    "    N=X.shape[0]\n",
    "    # initialize the cost vector of data\n",
    "    cost_sg=np.zeros((N,1))\n",
    "    # randomly assign group label for each sample\n",
    "    group_label=np.random.randint(1,Group_Number,(N,1))\n",
    "    # sample the cost for each sample\n",
    "    for i in range(0,N):\n",
    "        mean=Cost_Mean[int(group_label[i,0]),0];\n",
    "        var=Cost_Var[int(group_label[i,0]),0];\n",
    "        cost=np.random.normal(mean,var,1);\n",
    "        cost_sg[i,0]=cost;\n",
    "    \n",
    "    cost_sg=cost_sg/np.sum(cost_sg, axis=0)*N\n",
    "    return cost_sg\n",
    "\n",
    "'''\n",
    "function convex_cff and linear_cff are two functions that map a specific feature to a cost\n",
    "Input 'a','b','c' the parameter in the function ,'x' the feature\n",
    "'''\n",
    "\n",
    "def convex_cff(a,b,c,x):\n",
    "    cost=a*np.multiply(x,x)+b*x+c\n",
    "    return cost\n",
    "\n",
    "def linear_cff(a,b,x):\n",
    "    cost=a*x+b\n",
    "    return cost\n",
    "\n",
    "'''\n",
    "This function is for generate features correlated with features, \n",
    "Input: X, generated features\n",
    "       coeff: cost function parameter for every feature,\n",
    "       for exaple, if I use convex_cff, then for each feature i I have [coeff[i,0],coeff[i,1],coeff[i,2]]\n",
    "       corresponding to a,b c in the function\n",
    "       w: weight parameter for every features\n",
    "Output: the normalized output cost correlated with features\n",
    "'''\n",
    "\n",
    "\n",
    "def generate_cost_Features(X,coeff,w):\n",
    "    N=X.shape[0]\n",
    "    d=X.shape[1]\n",
    "    # calculate the cost for each features\n",
    "    for i in range(0,d):\n",
    "        X[:,i]=convex_cff(coeff[i,0],coeff[i,1],coeff[i,2],X[:,i])\n",
    "    cost_fts=np.dot(X,w)\n",
    "    # normalized cost, for each data set the total cost is the number of its data points\n",
    "    cost_fts=cost_fts/np.sum(cost_fts, axis=0)*N\n",
    "    return cost_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.92711191  0.52823456 -0.84195288 -0.50882052  0.68765288]\n",
      " [ 0.42468134 -0.92163989  0.72315875 -0.33188374 -0.01161615]\n",
      " [ 0.13243534 -0.22824276  0.28808314 -0.6732574   0.61992784]\n",
      " ..., \n",
      " [ 0.83489957  0.42418007 -0.72573145  0.24859215  0.51895011]\n",
      " [-0.88537941  0.80247989 -0.36503104 -0.42941014 -0.6434581 ]\n",
      " [ 0.03722929 -0.51082025  0.03310437  0.48793054 -0.07286725]] [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " ..., \n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n",
      "[[ 1.03794552]\n",
      " [ 1.03787485]\n",
      " [ 1.03488184]\n",
      " ..., \n",
      " [ 1.03305227]\n",
      " [ 1.03177359]\n",
      " [ 0.77641804]]\n",
      "[[ 1.19253475]\n",
      " [ 0.94436918]\n",
      " [ 1.15933325]\n",
      " ..., \n",
      " [ 1.19473433]\n",
      " [ 0.81847624]\n",
      " [ 0.80868319]]\n"
     ]
    }
   ],
   "source": [
    "#Initialize the number of samples, data points and noise level\n",
    "N=10000\n",
    "d=5\n",
    "sigma=0.01\n",
    "# generate data based on logistic regression model\n",
    "[X_lr,y_lr,h_lr]=generate_data_lr(N,d,sigma)\n",
    "print X_lr,y_lr\n",
    "np.savetxt('X_lr.txt', X_lr, delimiter=',')\n",
    "np.savetxt('y_lr.txt', y_lr, delimiter=',')\n",
    "np.savetxt('h_lr.txt',h_lr,delimiter=',')\n",
    "\n",
    "#Initialize the parameter for generate the cost correlated with sample groups\n",
    "Group_Number=5;\n",
    "Cost_Mean=np.random.randint(5,10,(Group_Number,1))\n",
    "sigma_cost=0.01\n",
    "Cost_Var=sigma_cost*np.random.randint(1,5,(Group_Number,1))\n",
    "cost_sg=generate_cost_SampleGroup(Group_Number, Cost_Mean,Cost_Var,X_lr)\n",
    "print cost_sg   \n",
    "np.savetxt('cost_sg.txt', cost_sg, delimiter=',')\n",
    "\n",
    "#Initialize the parameter for generate the cost correlated with features\n",
    "Group_Number=5;\n",
    "coeff=np.random.uniform(0.0,1.0,(d,3))\n",
    "w=np.random.uniform(0.0,1.0,(d,1))\n",
    "cost_fts=generate_cost_Features(X_lr,coeff,w)\n",
    "print cost_fts\n",
    "np.savetxt('cost_fts.txt', cost_fts, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0141f6f176fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_lr' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "\n",
    "class GradientDescent(object):\n",
    "    \"\"\"\n",
    "    Implementation of a gradient descent algorithm for binary classification.\n",
    "    The loss function is 1 if classified incorrectly, 0 if correctly,\n",
    "      but use a hinge loss for training.\n",
    "    Initialized with a list of digits to be labeled positively\n",
    "      (all others negatively).\n",
    "    The algorithm initializes self.w to be a vector of 0's.\n",
    "    Then for each of a sequence of rounds, check if the loss is positive;\n",
    "        if so do a gradient descent update.\n",
    "    Supports methods:\n",
    "        reset(eta)\n",
    "        norm_grad_loss(x, y)\n",
    "        test_error(X, Y)\n",
    "        data_update(x, y, importance_wt)\n",
    "        null_update()\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, pos_labels, eta=0.1):\n",
    "        # num_features = length of the x vector\n",
    "        # pos_labels   = list of digits in [0,9] to label positively (others negatively)\n",
    "        self.num_features = num_features\n",
    "        self.binarized_labels = [1.0 if l in pos_labels else -1.0 for l in range(10)]\n",
    "        self.reset(eta)\n",
    "        super(GradientDescent, self).__init__()\n",
    "\n",
    "    def reset(self, eta):\n",
    "        self.eta = eta\n",
    "        self.w = np.zeros(self.num_features)\n",
    "        self.avg_w = self.w\n",
    "        self.steps = 0\n",
    "    \n",
    "    # predict on only a single datapoint, using avg_w\n",
    "    def _predict_one(self,x):\n",
    "        return np.sign(self.avg_w.dot(x))\n",
    "\n",
    "    # predict on a matrix of data (shape is numdata * numfeatures)\n",
    "    def _predict(self,X):\n",
    "        Ypreds = np.apply_along_axis(self._predict_one, 1, X)\n",
    "        return Ypreds\n",
    "\n",
    "    # predict and report error on data (shape is numdata * numfeatures)\n",
    "    def test_error(self, X, Y):\n",
    "        Ypred = self._predict(X)\n",
    "        return np.mean(map(lambda y : self.binarized_labels[y], Y) != Ypred)\n",
    "\n",
    "    def _loss(self,x,biny):\n",
    "        score = self.w.dot(x) * biny\n",
    "        return max(1. - score, 0.)\n",
    "\n",
    "    def _grad_loss(self, x, biny):\n",
    "        # gradient of the loss\n",
    "        loss = self._loss(x,biny)\n",
    "        if loss > 0.:\n",
    "            return -biny * x\n",
    "        return np.zeros(self.num_features)\n",
    "\n",
    "    def norm_grad_loss(self, x, y):\n",
    "        # l2 norm of the gradient of the loss\n",
    "        return np.linalg.norm(self._grad_loss(x,self.binarized_labels[y]))\n",
    "\n",
    "    def _step(self):\n",
    "        # every step, whether we got a data_update or a null_update, we need to\n",
    "        # step the average\n",
    "        self.avg_w = (self.avg_w * self.steps + self.w) / float(self.steps + 1.0)\n",
    "        self.steps += 1\n",
    "\n",
    "    # Do an importance-weighted gradient descent update on the hypothesis\n",
    "    def data_update(self, x, y, importance_wt):\n",
    "        biny = self.binarized_labels[y]\n",
    "        loss = self._loss(x,biny)\n",
    "        if loss > 0.:\n",
    "            step = self.eta * self._grad_loss(x, biny)\n",
    "            self.w = self.w - step / importance_wt\n",
    "        self._step()\n",
    "\n",
    "    # Do an update with no new data\n",
    "    def null_update(self):\n",
    "        self._step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "\n",
    "# Rather than initializing with prior knowledge, we simply estimate gamma\n",
    "# online with a simple heuristic and set the normalizer K accordingly.\n",
    "\n",
    "# Estimating gamma:\n",
    "# We are using an importance-weighted estimate of gamma from the past data, i.e:\n",
    "#   gamma = (1/(# steps))*(sum_{t < now} {0 if we did not observe t,  else this_round_gamma / q_t}\n",
    "# where this_round_gamma = Delta(h_t,loss(.,z_t)) * (2sqrt(cmax) - sqrt(max(c*, c_t)))\n",
    "# and   q_t = Pr[ we posted a price higher than c_t for z_t ].\n",
    "\n",
    "# We also allow for discounting of past data by use of a discount factor.\n",
    "# This allows for forgetting past data as things change. Thus, the actual estimate is\n",
    "#   numerator = sum_{t <= s} discount^{s-t} {0 if not observe t, else .... }\n",
    "#   denominator = sum_{t <= s} discount^{s-t}\n",
    "#   gamma = numerator / denominator\n",
    "# For the paper we used discount=1, which reduces to the first, simpler estimator.\n",
    "\n",
    "# We initialize the numerator by 0 and denominator by a + b * T^c,\n",
    "# which is intended to act as a regularizer so we start with some momentum to buy points\n",
    "# and slowly decrease the buying rate as appropriate.\n",
    "\n",
    "\n",
    "INIT_GAMMA_A = 10.0\n",
    "INIT_GAMMA_B = 0.00001\n",
    "INIT_GAMMA_C = 0.1\n",
    "DISCOUNT = 1.0  # a discount factor for estimating gamma, if < 1, then old data is slowly forgotten\n",
    "\n",
    "class OurMech(object):\n",
    "    \"\"\"\n",
    "    This is our mechanism.\n",
    "    It is initialized for either the usual setting (default),\n",
    "  or \"at-cost\" (pay only the cost rather than your posted price).\n",
    "    \"\"\"\n",
    "    def __init__(self, alg, seed, T=1, B=1, eta=0.1, cmax=1.0, atcost = False):\n",
    "        self.alg = alg\n",
    "        self.randgen = random.Random(seed)\n",
    "        self.atcost = atcost\n",
    "        self.reset(eta, T, B, cmax=cmax)\n",
    "        super(OurMech, self).__init__()\n",
    "\n",
    "    # cmax = maximum cost\n",
    "    def reset(self, eta, T, B, cmax = 1.0):\n",
    "        self.T = T\n",
    "        self.B = B\n",
    "        self.cmax = cmax\n",
    "        self.spend = 0\n",
    "        self.step = 0\n",
    "        self.gamma_num = 0.0  # numerator\n",
    "        self.gamma_den = INIT_GAMMA_A + INIT_GAMMA_B * float(T)**INIT_GAMMA_C\n",
    "        self.gamma = self.gamma_num / self.gamma_den\n",
    "        self.alg.reset(eta)\n",
    "\n",
    "    # given quantile = Pr[price >= x], find and return x\n",
    "    def _get_price(self, quantile, delta, K):\n",
    "        if K == 0.0:\n",
    "            return self.cmax\n",
    "        val = delta / (K * quantile)\n",
    "        return min(self.cmax , val ** 2.0)\n",
    "\n",
    "    # return the probability price exceeds c\n",
    "    def _prob_exceeds(self, c, delta, K):\n",
    "        if K == 0.0 or c == 0.0:\n",
    "            return 1.0\n",
    "        return min(1.0 , delta / (K * c**0.5))\n",
    "\n",
    "    # update our estimate of gamma (using it to set the normalizer K next round)\n",
    "    def _update_gamma(self, cost, price, K, delta, prob_purchase):\n",
    "        self.gamma_num *= DISCOUNT  # we will add something if we obtain the point\n",
    "        self.gamma_den = self.gamma_den*DISCOUNT + 1.0\n",
    "        if price >= cost:\n",
    "            if self.atcost:\n",
    "                self.gamma_num += delta * cost**0.5 / prob_purchase  # importance-weighted\n",
    "            else:\n",
    "                cstar = self.cmax if K == 0.0 else min(self.cmax, (delta / K)**2.0)\n",
    "                self.gamma_num += delta * (2.0*self.cmax**0.5 - max(cost, cstar)**0.5) / prob_purchase\n",
    "        self.gamma = self.gamma_num / self.gamma_den\n",
    "\n",
    "    def _train(self, costs, Xtrain, Ytrain):\n",
    "        for i in xrange(len(costs)):\n",
    "            self.step += 1\n",
    "            delta = self.alg.norm_grad_loss(Xtrain[i], Ytrain[i])\n",
    "            c = costs[i]\n",
    "            K = self.gamma * float(self.T - self.step) / (self.B - self.spend)\n",
    "            quantile = self.randgen.random()\n",
    "            price = self._get_price(quantile, delta, K)\n",
    "            if price >= c:  # obtain the point\n",
    "                prob_purchase = self._prob_exceeds(c, delta, K)\n",
    "                self.alg.data_update(Xtrain[i], Ytrain[i], prob_purchase)\n",
    "                if self.atcost:\n",
    "                    self.spend += c\n",
    "                else:\n",
    "                    self.spend += price\n",
    "                if self.spend >= self.B:\n",
    "                    break\n",
    "                self._update_gamma(c, price, K, delta, prob_purchase)\n",
    "            else:\n",
    "                self.alg.null_update()\n",
    "\n",
    "    def train_and_get_err(self, costs, Xtrain, Ytrain, Xtest, Ytest):\n",
    "        self._train(costs, Xtrain, Ytrain)\n",
    "        return self.alg.test_error(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_lr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FRACTION = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "def gen_seed():\n",
    "    return random.randint(0,sys.maxint-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mech = OurMech(GradientDescent(len(X_lr[0]), [1]), gen_seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "budgets = map(float, [40, 80, 160, 320])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(Xlist, Ylist, costs):\n",
    "    # divide the dataset into train and test\n",
    "    num_train_points = int(len(Xlist) * TRAIN_FRACTION)\n",
    "    indices = range(len(Xlist))\n",
    "    random.shuffle(indices)\n",
    "    Xtrain = [Xlist[i] for i in indices[0:num_train_points]]\n",
    "    Ytrain = [Ylist[i] for i in indices[0:num_train_points]]\n",
    "    Costtrain = [costs[i] for i in indices[0:num_train_points]]\n",
    "    Xtest  = [Xlist[i] for i in indices[num_train_points:-1]]\n",
    "    Ytest  = [Ylist[i] for i in indices[num_train_points:-1]]\n",
    "    Costtest = [costs[i] for i in indices[num_train_points:-1]]\n",
    "    return (Xtrain,Ytrain,Costtrain, Xtest,Ytest, Costtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_seed = gen_seed()  # so we can record it and reproduce the entire experiment\n",
    "random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xlist = X_lr\n",
    "Ylist = [int(y) for y in y_lr]\n",
    "num_examples = [0]*2\n",
    "for y in Ylist:\n",
    "    num_examples[y] += 1    # labels are 0,...,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errs = [0.0]*len(budgets)\n",
    "squared_errs = [0.0]*len(budgets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRIALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 0\n",
      "TRIAL 1\n",
      "TRIAL 2\n",
      "TRIAL 3\n",
      "TRIAL 4\n",
      "TRIAL 5\n",
      "TRIAL 6\n",
      "TRIAL 7\n",
      "TRIAL 8\n",
      "TRIAL 9\n"
     ]
    }
   ],
   "source": [
    "(Xtrain,Ytrain,Costtrain, Xtest,Ytest, Costtest) = split_dataset(Xlist, Ylist, cost_fts)\n",
    "T = len(Xtrain)\n",
    "num_features = len(Xtrain[0])\n",
    "avg_data_norm = np.apply_along_axis(np.linalg.norm, 1, Xtrain).mean()\n",
    "eta = 0.1 / avg_data_norm  # rough heuristic, because the norm of the data is not normalized [0,1]\n",
    "\n",
    "for trial in xrange(TRIALS):\n",
    "    print \"TRIAL \" + str(trial)\n",
    "    for bi,B in enumerate(budgets):\n",
    "        mech.reset(eta, T, B, cmax=1.0)\n",
    "        temp = mech.train_and_get_err([i[0]/10 for i in Costtrain], Xtrain, Ytrain, Xtest, Ytest)\n",
    "        errs[bi] += temp / float(TRIALS)\n",
    "        squared_errs[bi] += temp*temp / float(TRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.39142126902989222,\n",
       "  0.23804867207467501,\n",
       "  0.22401377930881211,\n",
       "  0.21557950883431495],\n",
       " [0.16038290533226018,\n",
       "  0.057298423633666454,\n",
       "  0.050280206091721534,\n",
       "  0.046479636876347381])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs, squared_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib, matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10531de50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niNREwSEiIjVRcIiISE0UHCIiUpP/A1gELuNe07NeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1054c3850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(budgets,errs, linewidth=1.5)\n",
    "plt.title(\"Chen/Waggoner Algorithm with Correlated Features\")\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 0\n",
      "TRIAL 1\n",
      "TRIAL 2\n",
      "TRIAL 3\n",
      "TRIAL 4\n",
      "TRIAL 5\n",
      "TRIAL 6\n",
      "TRIAL 7\n",
      "TRIAL 8\n",
      "TRIAL 9\n"
     ]
    }
   ],
   "source": [
    "(Xtrain,Ytrain,Costtrain, Xtest,Ytest, Costtest) = split_dataset(Xlist, Ylist, cost_sg)\n",
    "T = len(Xtrain)\n",
    "num_features = len(Xtrain[0])\n",
    "avg_data_norm = np.apply_along_axis(np.linalg.norm, 1, Xtrain).mean()\n",
    "eta = 0.1 / avg_data_norm  # rough heuristic, because the norm of the data is not normalized [0,1]\n",
    "\n",
    "for trial in xrange(TRIALS):\n",
    "    print \"TRIAL \" + str(trial)\n",
    "    for bi,B in enumerate(budgets):\n",
    "        mech.reset(eta, T, B, cmax=1.0)\n",
    "        temp = mech.train_and_get_err([i[0]/10 for i in Costtrain], Xtrain, Ytrain, Xtest, Ytest)\n",
    "        errs[bi] += temp / float(TRIALS)\n",
    "        squared_errs[bi] += temp*temp / float(TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1057bc450>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMzMbED+P8wCPvLhUkwvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10596fc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(budgets,errs, linewidth=1.5)\n",
    "plt.title(\"Chen/Waggoner Algorithm with Correlated Sample Group\")\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
