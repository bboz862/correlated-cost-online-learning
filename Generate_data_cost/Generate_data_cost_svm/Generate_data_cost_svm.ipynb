{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.78223159]\n",
      " [-2.08963526]\n",
      " [-0.6248035 ]\n",
      " [ 1.68417013]\n",
      " [-1.8062876 ]]\n",
      "[[-2.88163162]\n",
      " [ 1.29206954]\n",
      " [-3.22233506]\n",
      " ..., \n",
      " [ 1.20086682]\n",
      " [-1.79781144]\n",
      " [-1.01074941]]\n",
      "[-0.00296964]\n",
      "[[-0.68014713 -0.54136596 -0.16993897 -0.45847895  0.42913206]\n",
      " [ 0.1065499  -0.53380322 -0.14139506 -0.07560167  0.10262001]\n",
      " [-0.50192915  0.60379836  0.51325333 -0.87750649 -0.96009011]\n",
      " ..., \n",
      " [-0.75395089 -0.520391   -0.93272222  0.468363   -0.89043289]\n",
      " [ 0.04681066  0.11807679  0.38667969 -0.91449007 -0.03725255]\n",
      " [ 0.74806451  0.44756124  0.39681225 -0.75427406  0.77410003]] [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 1.2852017 ]\n",
      " [ 0.71349939]\n",
      " [ 1.28357704]\n",
      " ..., \n",
      " [ 1.28505093]\n",
      " [ 1.29252337]\n",
      " [ 1.14147907]]\n",
      "[[ 0.8446533 ]\n",
      " [ 0.74687355]\n",
      " [ 1.0592945 ]\n",
      " ..., \n",
      " [ 0.8409615 ]\n",
      " [ 0.88851482]\n",
      " [ 1.34985887]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "'''\n",
    "This function is to generate data with binary label, based on the model of support vector machine,\n",
    "Which is just to find a separating hyperplane of the data\n",
    "'X' is sampled from a uniform distribution between [0,1]\n",
    "hypothesis 'h' is generated from a integer uniform distribution between [-5,5]\n",
    "the noise level 'sigma' is generated from a normal distribution with mean 0 and std sigma\n",
    "label y is generated in the way below:\n",
    "if Ax+b>0 then y=1 else y=0\n",
    "reference A and b are stored in the parameter 'hyp'\n",
    "\n",
    "Input: number of samples N,dimension of data d, noise level sigma\n",
    "\n",
    "Output: generate X, label y, realy hypothesis hyp\n",
    "'''\n",
    "\n",
    "def generate_data_svm(N,d,sigma):\n",
    "    # generate X uniform distributed between[-1,1]\n",
    "    X=np.random.uniform(-1,1,size=(N,d))\n",
    "    # generate noise normal distributed, mean 0, variance sigam^2\n",
    "    noise=np.random.normal(0.0,sigma,(N,1))\n",
    "    # generate hypothesis of the linear classification, it is d+1 dimension vector\n",
    "    h=np.random.uniform(-5.0,5.0,size=(d,1))\n",
    "    print h\n",
    "    # generate value of y if it is a linear regression problem\n",
    "    y_linear=np.dot(X,h)+noise\n",
    "    print y_linear\n",
    "    avg_y=np.sum(y_linear,axis=0)/N\n",
    "    print avg_y\n",
    "    b=avg_y*np.ones((N,1))\n",
    "    # transform y_linear into a  0-1 label based on logistic regression model\n",
    "    y=y_linear-b\n",
    "    #y=1 / (1 + np.exp(-y_linear))\n",
    "    for i in range(0,N):\n",
    "        if y[i,0]>=0:\n",
    "            y[i,0]=1\n",
    "        else:\n",
    "            y[i,0]=0\n",
    "    hyp=np.zeros((d+1,1))\n",
    "    hyp[0:d,0]=h[0:d,0]\n",
    "    hyp[d,0]=-avg_y\n",
    "    return X,y,hyp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "function generate_cost_SampleGroup is to generate cost correlated with their group\n",
    "first randomly assign a group label for each sample, \n",
    "In each group, the cost is a normal distribution with a specific mean and variance\n",
    "Input:\n",
    "'Group_Number' is a integer showing the number of groups\n",
    "'Cost_Mean' is a 1-D vector contains the cost mean of each group\n",
    "'Cost_Var' is a 1-D vector contains the cost variance of each group\n",
    "'X' generated data\n",
    "'cost_sg' is a sample\n",
    "'''\n",
    "\n",
    "\n",
    "def generate_cost_SampleGroup(Group_Number,Cost_Mean,Cost_Var,X):\n",
    "    # number of samples\n",
    "    N=X.shape[0]\n",
    "    # initialize the cost vector of data\n",
    "    cost_sg=np.zeros((N,1))\n",
    "    # randomly assign group label for each sample\n",
    "    group_label=np.random.randint(1,Group_Number,(N,1))\n",
    "    # sample the cost for each sample\n",
    "    for i in range(0,N):\n",
    "        mean=Cost_Mean[int(group_label[i,0]),0];\n",
    "        var=Cost_Var[int(group_label[i,0]),0];\n",
    "        cost=np.random.normal(mean,var,1);\n",
    "        cost_sg[i,0]=cost;\n",
    "    \n",
    "    cost_sg=cost_sg/np.sum(cost_sg, axis=0)*N\n",
    "    return cost_sg\n",
    "\n",
    "'''\n",
    "function convex_cff and linear_cff are two functions that map a specific feature to a cost\n",
    "Input 'a','b','c' the parameter in the function ,'x' the feature\n",
    "'''\n",
    "\n",
    "def convex_cff(a,b,c,x):\n",
    "    cost=a*np.multiply(x,x)+b*x+c\n",
    "    return cost\n",
    "\n",
    "def linear_cff(a,b,x):\n",
    "    cost=a*x+b\n",
    "    return cost\n",
    "\n",
    "'''\n",
    "This function is for generate features correlated with features, \n",
    "Input: X, generated features\n",
    "       coeff: cost function parameter for every feature,\n",
    "       for exaple, if I use convex_cff, then for each feature i I have [coeff[i,0],coeff[i,1],coeff[i,2]]\n",
    "       corresponding to a,b c in the function\n",
    "       w: weight parameter for every features\n",
    "Output: the normalized output cost correlated with features\n",
    "'''\n",
    "\n",
    "\n",
    "def generate_cost_Features(X,coeff,w):\n",
    "    N=X.shape[0]\n",
    "    d=X.shape[1]\n",
    "    # calculate the cost for each features\n",
    "    for i in range(0,d):\n",
    "        X[:,i]=convex_cff(coeff[i,0],coeff[i,1],coeff[i,2],X[:,i])\n",
    "    cost_fts=np.dot(X,w)\n",
    "    # normalized cost, for each data set the total cost is the number of its data points\n",
    "    cost_fts=cost_fts/np.sum(cost_fts, axis=0)*N\n",
    "    return cost_fts\n",
    "\n",
    "\n",
    "'''\n",
    "main part of the data generating file\n",
    "'''\n",
    "\n",
    "#Initialize the number of samples, data points and noise level\n",
    "N=10000\n",
    "d=5\n",
    "sigma=0.01\n",
    "# generate data based on separating hyperplane model\n",
    "[X_svm,y_svm,h_svm]=generate_data_svm(N,d,sigma)\n",
    "print X_svm,y_svm\n",
    "np.savetxt('X_svm.txt', X_svm, delimiter=',')\n",
    "np.savetxt('y_svm.txt', y_svm, delimiter=',')\n",
    "np.savetxt('h_svm.txt',h_svm,delimiter=',')\n",
    "\n",
    "#Initialize the parameter for generate the cost correlated with sample groups\n",
    "Group_Number=5;\n",
    "Cost_Mean=np.random.randint(5,10,(Group_Number,1))\n",
    "sigma_cost=0.01\n",
    "Cost_Var=sigma_cost*np.random.randint(1,5,(Group_Number,1))\n",
    "cost_sg=generate_cost_SampleGroup(Group_Number, Cost_Mean,Cost_Var,X_svm)\n",
    "print cost_sg   \n",
    "np.savetxt('cost_sg.txt', cost_sg, delimiter=',')\n",
    "\n",
    "#Initialize the parameter for generate the cost correlated with features\n",
    "Group_Number=5;\n",
    "coeff=np.random.uniform(0.0,1.0,(d,3))\n",
    "w=np.random.uniform(0.0,1.0,(d,1))\n",
    "cost_fts=generate_cost_Features(X_svm,coeff,w)\n",
    "print cost_fts\n",
    "np.savetxt('cost_fts.txt', cost_sg, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
